{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlATiAkwfZ3dNAMvYZyYu1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aatika-hakim/chatbots/blob/main/customer_support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langgraph langchain_google_genai langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "86bW3iUZQ2nA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "iSXuN84DQigR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "6CGpFizLQjRi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "_-C5Znl7Qnqa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
        "# llm.invoke(\"hi\").content\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=1, api_key= api_key)\n",
        "llm.invoke(\"hi\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "1gtx7uE9QqGT",
        "outputId": "fa0cf884-dc2f-4f1b-9698-4a1361ebed74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TimeoutException",
          "evalue": "Requesting secret GROQ_API_KEY timed out. Secrets can only be fetched when running from the Colab UI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-130320c422c3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GROQ_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_groq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGroq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutException\u001b[0m: Requesting secret GROQ_API_KEY timed out. Secrets can only be fetched when running from the Colab UI."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "2vPPqD0hQxcO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "hmeg7EfPQ738",
        "outputId": "9a0e02ae-08e0-4939-a979-84bc2e35bd8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "id": "W7UL2T5YRA_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQYoZL_9RJFY",
        "outputId": "93a3affb-9006-42f7-c6c6-cb5cc6ff3ed6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c144881b280>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "id": "6O2jYq7KRWRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define customer support keywords or intents\n",
        "SUPPORT_KEYWORDS = [\n",
        "    \"complaint\", \"refund\", \"support\", \"issue\", \"problem\",\n",
        "    \"help\", \"order\", \"billing\", \"payment\", \"service\"\n",
        "]\n",
        "\n",
        "# Function to check if input is a customer support query\n",
        "def is_customer_support_query(user_input):\n",
        "    user_input = user_input.lower()\n",
        "    return any(keyword in user_input for keyword in SUPPORT_KEYWORDS)\n",
        "\n",
        "# Function to process customer support queries\n",
        "def handle_customer_support(user_input):\n",
        "    if \"complaint\" in user_input:\n",
        "        return \"Please describe your issue, including the product and your preferred resolution.\"\n",
        "    elif \"refund\" in user_input:\n",
        "        return \"To process a refund, we need the order ID and the reason for the refund.\"\n",
        "    elif \"help\" in user_input:\n",
        "        return \"How can I assist you today? You can ask about complaints, refunds, or other support issues.\"\n",
        "    else:\n",
        "        return \"Can you provide more details about your support request?\"\n",
        "\n",
        "# Main chatbot loop\n",
        "def customer_support_chatbot():\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"User: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"Goodbye! Have a great day!\")\n",
        "                break\n",
        "\n",
        "            # Check if the input is a valid support query\n",
        "            if is_customer_support_query(user_input):\n",
        "                response = handle_customer_support(user_input)\n",
        "            else:\n",
        "                response = \"I'm here to assist with customer support issues only. Please ask a relevant question.\"\n",
        "\n",
        "            print(\"Chatbot:\", response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            break\n",
        "\n",
        "# Run the chatbot\n",
        "customer_support_chatbot()\n"
      ],
      "metadata": {
        "id": "2vlwzkh0X3My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit langchain_anthropic gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KprntmE5UGsu",
        "outputId": "1c606859-e3d9-4084-9159-f618a50db477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.tools import tool\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain.agents import AgentExecutor, Tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from typing_extensions import TypedDict\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Load environment variables and set OpenAI API key\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "\n",
        "# Setup LLM\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "\n",
        "# Memory setup\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "# Define the state structure\n",
        "class State(TypedDict):\n",
        "    query: str\n",
        "    category: str\n",
        "    response: str\n",
        "\n",
        "# Restaurant-specific tools\n",
        "\n",
        "@tool\n",
        "def menu_search(state: State) -> str:\n",
        "    \"\"\"Provide information about menu items or specials.\"\"\"\n",
        "    menu_query = state.get(\"query\", \"\").strip()\n",
        "    if not menu_query:\n",
        "        return \"Please provide a specific menu item or query.\"\n",
        "\n",
        "    # Simulate menu search\n",
        "    menu_items = [\"Pizza\", \"Burger\", \"Pasta\", \"Salad\", \"Dessert\"]\n",
        "    if menu_query.lower() in [item.lower() for item in menu_items]:\n",
        "        return f\"Here's information about {menu_query}.\"\n",
        "    return \"Sorry, we couldn't find that item on the menu.\"\n",
        "\n",
        "@tool\n",
        "def order_status(state: State) -> str:\n",
        "    \"\"\"Track or modify a customer's order.\"\"\"\n",
        "    order_id = state.get(\"query\", \"\").strip()\n",
        "    if not order_id:\n",
        "        return \"Please provide your order ID.\"\n",
        "\n",
        "    # Simulate order status lookup\n",
        "    return f\"Your order {order_id} is being prepared and should arrive shortly.\"\n",
        "\n",
        "@tool\n",
        "def reservation_tool(state: State) -> str:\n",
        "    \"\"\"Handle restaurant reservations.\"\"\"\n",
        "    reservation_query = state.get(\"query\", \"\").strip()\n",
        "    if not reservation_query:\n",
        "        return \"Please provide details like the number of people and time for your reservation.\"\n",
        "\n",
        "    # Simulate reservation handling\n",
        "    return f\"Your reservation for {reservation_query} has been confirmed.\"\n",
        "\n",
        "@tool\n",
        "def feedback_complaints(state: State) -> str:\n",
        "    \"\"\"Handle customer complaints or feedback.\"\"\"\n",
        "    feedback = state.get(\"query\", \"\").strip()\n",
        "    if not feedback:\n",
        "        return \"Please provide details of your complaint or feedback.\"\n",
        "\n",
        "    # Simulate handling feedback\n",
        "    return f\"Thank you for your feedback! We will look into it shortly.\"\n",
        "\n",
        "# Tools\n",
        "tools = [\n",
        "    Tool(name=\"menu_search\", func=menu_search, description=\"Search the menu for items or specials.\"),\n",
        "    Tool(name=\"order_status\", func=order_status, description=\"Check the status of an order.\"),\n",
        "    Tool(name=\"reservation_tool\", func=reservation_tool, description=\"Make or modify restaurant reservations.\"),\n",
        "    Tool(name=\"feedback_complaints\", func=feedback_complaints, description=\"Handle complaints or feedback.\"),\n",
        "]\n",
        "\n",
        "# Agent Executor\n",
        "agent = AgentExecutor(agent=llm, tools=tools, verbose=True)\n",
        "\n",
        "def use_tool(state: State) -> State:\n",
        "    \"\"\"Use LangChain tools to handle specific tasks.\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    try:\n",
        "        response = agent.run(query)\n",
        "        state[\"response\"] = response\n",
        "    except Exception as e:\n",
        "        state[\"response\"] = f\"An error occurred: {str(e)}\"\n",
        "    return state\n",
        "\n",
        "# Categorize restaurant queries\n",
        "def categorize_query(state: State) -> State:\n",
        "    \"\"\"Categorize the query into relevant restaurant support categories.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        Categorize the following query into one of these categories:\n",
        "        'Menu Inquiry', 'Order Issues', 'Reservation', 'Feedback/Complaints', or 'General Assistance'.\n",
        "        Query: {query}\n",
        "\n",
        "        Conversation History:\n",
        "        {history}\n",
        "        \"\"\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    category = chain.invoke({\"query\": state[\"query\"], \"history\": memory.buffer}).content\n",
        "    state[\"category\"] = category\n",
        "    memory.save_context({\"Human\": state[\"query\"]}, {\"AI\": category})\n",
        "    return state\n",
        "\n",
        "# Routing logic\n",
        "def route_query(state: State) -> str:\n",
        "    \"\"\"Route the query based on its category.\"\"\"\n",
        "    category = state.get(\"category\", \"\")\n",
        "    if category == \"Menu Inquiry\":\n",
        "        return \"menu_search\"\n",
        "    elif category == \"Order Issues\":\n",
        "        return \"order_status\"\n",
        "    elif category == \"Reservation\":\n",
        "        return \"reservation_tool\"\n",
        "    elif category == \"Feedback/Complaints\":\n",
        "        return \"feedback_complaints\"\n",
        "    else:\n",
        "        return \"handle_general_assistance\"\n",
        "\n",
        "# Handle general assistance\n",
        "def handle_general_assistance(state: State) -> State:\n",
        "    \"\"\"Provide general assistance for restaurant-related queries.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Provide general assistance for the following query: {query}\\n\\nConversation History:\\n{history}\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\"query\": state[\"query\"], \"history\": memory.buffer}).content\n",
        "    state[\"response\"] = response\n",
        "    memory.save_context({\"Human\": state[\"query\"]}, {\"AI\": response})\n",
        "    return state\n",
        "\n",
        "# Workflow setup\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"categorize_query\", categorize_query)\n",
        "workflow.add_node(\"menu_search\", menu_search)\n",
        "workflow.add_node(\"order_status\", order_status)\n",
        "workflow.add_node(\"reservation_tool\", reservation_tool)\n",
        "workflow.add_node(\"feedback_complaints\", feedback_complaints)\n",
        "workflow.add_node(\"handle_general_assistance\", handle_general_assistance)\n",
        "workflow.add_edge(START, \"categorize_query\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"categorize_query\", route_query,\n",
        "    [\"menu_search\", \"order_status\", \"reservation_tool\", \"feedback_complaints\", \"handle_general_assistance\"], END\n",
        ")\n",
        "\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "utRfYTDcUBm3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit UI Setup\n",
        "st.set_page_config(page_title=\"Restaurant Customer Support\", page_icon=\"🍽️\", layout=\"wide\")\n",
        "st.title(\"🍽️ Restaurant Customer Support Chatbot\")\n",
        "st.write(\"Welcome! I'm here to assist you with menu inquiries, order issues, reservations, feedback, and more.\")\n",
        "\n",
        "# Sidebar setup\n",
        "st.sidebar.title(\"🍴 Support Options\")\n",
        "st.sidebar.header(\"Choose an option:\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- **Menu Inquiry**: Get details on our menu items.\n",
        "- **Order Issues**: Track or modify your order.\n",
        "- **Reservation**: Make or change your reservation.\n",
        "- **Feedback/Complaints**: Let us know about your experience.\n",
        "- **General Assistance**: Ask anything else.\n",
        "\"\"\")\n",
        "\n",
        "# User chat interface\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# Display chat history\n",
        "def display_chat():\n",
        "    for message in st.session_state.history:\n",
        "        role = message[\"role\"]\n",
        "        if role == \"user\":\n",
        "            st.chat_message(\"user\").markdown(message[\"content\"])\n",
        "        elif role == \"assistant\":\n",
        "            st.chat_message(\"assistant\").markdown(message[\"content\"])\n",
        "\n",
        "# Input handler\n",
        "query = st.chat_input(\"💬 Type your question here...\")\n",
        "if query:\n",
        "    # Append user message to history\n",
        "    st.session_state.history.append({\"role\": \"user\", \"content\": query})\n",
        "\n",
        "    # Process query and route to appropriate function\n",
        "    state = {\"query\": query, \"category\": \"\", \"response\": \"\"}\n",
        "    result = app.invoke(state)\n",
        "\n",
        "    # Append AI response to history\n",
        "    st.session_state.history.append({\"role\": \"assistant\", \"content\": result[\"response\"]})\n",
        "\n",
        "# Display updated chat\n",
        "display_chat()\n",
        "\n",
        "# Reset conversation\n",
        "if st.sidebar.button(\"🔄 Reset Conversation\"):\n",
        "    st.session_state.history.clear()\n",
        "    st.sidebar.success(\"Conversation reset successfully!\")"
      ],
      "metadata": {
        "id": "LorkvRNAVhHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}